{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install cobaya"
      ],
      "metadata": {
        "id": "h8A178-FlKGU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cobaya-install cosmo -p /path/to/packages"
      ],
      "metadata": {
        "id": "kK1SISdBlcAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHhjNKeCgQtm"
      },
      "outputs": [],
      "source": [
        "# General python imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os, sys\n",
        "\n",
        "# Import corresponding modules from GetDist\n",
        "from getdist.mcsamples import loadMCSamples, MCSamplesFromCobaya\n",
        "import getdist.plots as gdplt\n",
        "\n",
        "\n",
        "# Matplotlib params set-up for nice plots\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rc('xtick',labelsize=16)\n",
        "plt.rc('ytick',labelsize=16)\n",
        "plt.rc('font',size=25)\n",
        "plt.rc('axes', titlesize=26)\n",
        "plt.rc('axes', labelsize=25)\n",
        "plt.rc('lines', linewidth=2)\n",
        "plt.rc('lines', markersize=6)\n",
        "plt.rc('legend', fontsize=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkot5xvKgQtn"
      },
      "source": [
        "# Advanced tutorial 2\n",
        "\n",
        "\n",
        "**Description**: this jupyter notebook is designed to help you solve the exercises planned for this advanced practical session. For this, we will use the CMB measurements of `Planck18` to deal as the observational probes to constrain the Standard Cosmological Model. We will use `Cobaya` as the main Bayesian Analysis tool and `CAMB` as the Boltzmann Solver.\n",
        "\n",
        "\n",
        "### Exercises:\n",
        "\n",
        "* **Exercise 0**: Plot the chains from the previous tutorial to see the evolution\n",
        "\n",
        "* **Exercise 1**: Make an evaluation of the posterior distribution by running Cobaya with its model wrapper and the CMB Temperture anisotropies likelihood of Planck18. Keep the cosmological values fixed. Think about the values of the likelihood and the posterior. What are we sampling?\n",
        "\n",
        "* **Exercise 2**: Plot the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given the parameters values fixed in exercise 1.\n",
        "\n",
        "* **Exercise 3**: Plot the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given a very different value for $\\Omega_b$. Compare with the result of exercise 2 by making a plot of the difference between the angular power spectra. Calculate the difference in the likelihood. Follow what you have learnt in exercise 1.\n",
        "\n",
        "* **Bonus exercise**: Repeat everything in exercises 1, 2 and 3 given a modified CAMB that contains a feature in the primordial power spectrum. This exercise will unveil the full power of Cobaya and why it is useful for the Euclid Consortium. There is a dedicated notebook called `Cobaya-BonusExercise.ipynb`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEVC-rWXgQtn"
      },
      "source": [
        "## Exercise 0:\n",
        "\n",
        "Plot the chains corresponding to the $\\Lambda$CDM model that you left running yesterday to see the evolution.\n",
        "\n",
        "Alternatively, plot the the chains in the corresponding tar file of the respository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6rkf2lngQto"
      },
      "outputs": [],
      "source": [
        "# Load the chains and the updated config file from the previous run\n",
        "gdsamples = loadMCSamples('/LCDM')\n",
        "\n",
        "gdplot_cartesian = gdplt.get_subplot_plotter(width_inch=5)\n",
        "gdplot_cartesian.triangle_plot(gdsamples, ['H0', 'ombh2', 'omch2', 'As', 'ns'], filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3uB5knwgQto"
      },
      "source": [
        "## Exercise 1:\n",
        "\n",
        "Make an evaluation of the posterior distribution by running Cobaya with its model wrapper and the Planck18 TT data set, keeping cosmological values fixed. Think about the values of the likelihood and the posterior. What are we sampling?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W7gbmtXgQto"
      },
      "outputs": [],
      "source": [
        "# We are running Cobaya with Planck18 data\n",
        "# Let's start by defining the corresponding config file\n",
        "# The options that can be modified by the user are pointed with the acronym (UC).\n",
        "# Note that currently all the parameters are fixed!\n",
        "\n",
        "# Fill the info dictionary yourself!\n",
        "\n",
        "# We are running Cobaya with Planck18 data\n",
        "# Let's start by defining the corresponding config file\n",
        "# The options that can be modified by the user are pointed with the acronym (UC).\n",
        "# Note that currently all the parameters are fixed!\n",
        "\n",
        "info = {\n",
        "    #'params': Cobaya's protected key of the input dictionary.\n",
        "    # Includes the parameters that the user would like to sample over:\n",
        "'params': {\n",
        "        # Each parameter below (which is a 'key' of another sub-dictionary) can contain a dictionary\n",
        "        # with the key 'prior', 'latex'...\n",
        "        # If the prior dictionary is not passed to a parameter, this parameter is fixed.\n",
        "        # In this example, we are sampling the parameter ns\n",
        "        # For more information see: https://cobaya.readthedocs.io/en/latest/example.html\n",
        "        'ombh2': 0.022445, #Omega density of baryons times the reduced Hubble parameter squared\n",
        "        'omch2': 0.1205579307, #Omega density of cold dark matter times the reduced Hubble parameter squared\n",
        "        'H0': 67, #Hubble parameter evaluated today (z=0) in km/s/Mpc\n",
        "        'tau': 0.0925, #optical depth\n",
        "        'mnu': 0.06, #  sum of the mass of neutrinos in eV\n",
        "        'nnu': 3.046, #N_eff of relativistic species\n",
        "        'As': 2.12605e-9, #Amplitude of the primordial scalar power spectrum\n",
        "        'ns': 0.965, # primordial power spectrum tilt (sampled with an uniform prior)\n",
        "        'w': -1, #Dark energy fluid model\n",
        "        'wa': 0, #Dark energy fluid model\n",
        "        'omk': 0.0, #curvature density\n",
        "        'omegam': None, #DERIVED parameter: Omega matter density\n",
        "        'omegab': None, #DERIVED parameter: Omega baryon density\n",
        "        'omeganu': None, #DERIVED parameter: Omega neutrino density\n",
        "        'omnuh2': None, #DERIVED parameter: Omega neutrino density times de reduced Hubble parameter squared\n",
        "        'omegac': None, #DERIVED parameter: Omega cold dark matter density\n",
        "        'N_eff': None},\n",
        "    # 'theory': Cobaya's protected key of the input dictionary.\n",
        "    # Cobaya needs to ask some minimum theoretical requirements to a Boltzman Solver\n",
        "    # you can choose between CAMB or CLASS\n",
        "    # In this notebook, we use CAMB and specify some CAMB arguments\n",
        "    # such as the number of massive neutrinos\n",
        "    # and the dark energy model\n",
        "    #\n",
        "    'theory': {'camb':\n",
        "               {'stop_at_error': True,\n",
        "                'extra_args':{'num_massive_neutrinos': 1,\n",
        "                              'dark_energy_model': 'ppf'}}},\n",
        "    #'sampler': Cobaya's protected key of the input dictionary.\n",
        "    # you can choose the sampler you want to use.\n",
        "    # Check Cobaya's documentation to see the list of available samplers\n",
        "    # In this exercise, we use the 'evaluate' sampler to make a single computation of the posterior distributions\n",
        "    # Note: if you want to run a simple MCMC sampling choose 'mcmc'\n",
        "    'sampler': {'evaluate': None},\n",
        "    # 'packages_path': Cobaya's protected key of the input dictionary.\n",
        "    # This is the variable you need to update\n",
        "    # if you are running Cobaya with cobaya_modules (option (2) above).\n",
        "    # If you are using the conda likelihood environment or option (1),\n",
        "    # please, keep the line below commented\n",
        "    #\n",
        "    #'packages_path': modules_path,\n",
        "    #\n",
        "    #'output': Cobaya's protected key of the input dictionary.\n",
        "    # Where are the results going to be stored, in case that the sampler produce output files?\n",
        "    # For example: chains...\n",
        "    # (UC): modify the path below within 'output' to choose a name and a directory for those files\n",
        "    'output': 'chains/euclid_school',\n",
        "    #'debug': Cobaya's protected key of the input dictionary.\n",
        "    # how much information you want Cobaya to print? If debug: True, it prints every single detail\n",
        "    # that is going on internally in Cobaya\n",
        "    'debug': False,\n",
        "    #'timing': Cobaya's protected key of the input dictionary.\n",
        "    # if timing: True, Cobaya returns how much time it took it to make a computation of the posterior\n",
        "    # and how much time take each of the modules to perform their tasks\n",
        "    'timing': True,\n",
        "    #'force': Cobaya's protected key of the input dictionary.\n",
        "    # if 'force': True, Cobaya forces deleting the previous output files, if found, with the same name\n",
        "    'force': True,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D5rs_scgQto"
      },
      "outputs": [],
      "source": [
        "# We import the likelihood of Planck18\n",
        "#'likelihood': Cobaya's protected key of the input dictionary.\n",
        "\n",
        "info['likelihood'] = {\n",
        "                'planck_NPIPE_highl_CamSpec.TTTEEE': None}\n",
        "\n",
        "# Print the full info!\n",
        "info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKVC6tNogQtp"
      },
      "outputs": [],
      "source": [
        "#First: import model wrapper of Cobaya\n",
        "from cobaya.model import get_model\n",
        "\n",
        "#Â The `get_model` wrapper of Cobaya imported in the line above needs a yaml or python dictionary as argument\n",
        "model = get_model(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpG1yKFbgQtp"
      },
      "outputs": [],
      "source": [
        "# Let's have an insight about what Cobaya has requested to CAMB to calculate the Planck18 likelihood\n",
        "\n",
        "# (1) Requirements needed by the likelihood code.\n",
        "# That means, which quantities are we asking to the Boltzman (CAMB/CLASS) through Cobaya?\n",
        "print('\\n Requirements \\n')\n",
        "print(model.provider.requirement_providers)\n",
        "# (2) At which values have the requirements been requested (redshift, scales...)?\n",
        "print('\\n Requested \\n')\n",
        "print(model.requested())\n",
        "print('\\n Parameters \\n')\n",
        "print(model.input_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FDg5THrgQtp"
      },
      "outputs": [],
      "source": [
        "# Let's get a random set of sampled parameters values\n",
        "point = dict(zip(model.parameterization.sampled_params(),\n",
        "                 model.prior.sample(ignore_external=True)[0]))\n",
        "print('Sampled parameters values: \\n', point)\n",
        "# Make a computation of the logposterior on a set of parameter values\n",
        "logposterior = model.logposterior(point)\n",
        "\n",
        "\n",
        "# Note that we are measuring the time for illustration purposes only.\n",
        "\n",
        "print('\\n Full log-posterior:')\n",
        "print('   logposterior: %g' % logposterior.logpost)\n",
        "print('   logpriors: %r' % dict(zip(list(model.prior), logposterior.logpriors)))\n",
        "print('   loglikelihoods: %r' % dict(zip(list(model.likelihood), logposterior.loglikes)))\n",
        "print('   derived params: %r' % dict(zip(list(model.parameterization.derived_params()), logposterior.derived)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2En4RTXngQtp"
      },
      "source": [
        "## Exercise 2:\n",
        "\n",
        "Plot the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given the values above. Have a look at https://cobaya.readthedocs.io/en/latest/cosmo_external_likelihood.html to get inspiration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS9pBk9YgQtq"
      },
      "outputs": [],
      "source": [
        "# Check the lines above to see which requirements were selected by the model when Planck18 was specified\n",
        "# In particular, look at model.provider\n",
        "\n",
        "\n",
        "Cls = model.provider.get_Cl(ell_factor=True, units=\"muK2\")\n",
        "Cls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh__5XkegQtq"
      },
      "outputs": [],
      "source": [
        "# Let's plot them!\n",
        "\n",
        "plt.plot(Cls['ell'][2:], Cls['ell'][2:] * (Cls['ell'][2:] + 1)*Cls['tt'][2:])\n",
        "plt.xlabel(r'$\\ell$')\n",
        "plt.ylabel(r'$C_\\ell^{TT}$');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGE7gV0ZgQtq"
      },
      "source": [
        "## Exercise 3:\n",
        "\n",
        "Plot again the CMB Temperature angular power spectra retrieved from `CAMB` via Cobaya given a very different value for $\\Omega_b$. Keep in mind that you need to fix the nuisance parameters of the Planck18 likelihood. How would you do it?\n",
        "\n",
        "Make a plot plotting the difference between the corresponding temperature angular power spectra. Calculate the difference in the likelihood value for both cases.\n",
        "\n",
        "To do this exercise, I recommend you creating a new model instance of the model wrapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-KEVTD0gQtq"
      },
      "outputs": [],
      "source": [
        "# Make a copy of the info dictionary and modify the entry corresponding to Omega_b\n",
        "info_modified_omegab = info.copy()\n",
        "info_modified_omegab['params']['ombh2'] = 10 * 0.022445"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn_98GuLgQtq"
      },
      "outputs": [],
      "source": [
        "# Create a new model instance with this modified info dictionary\n",
        "model_modified_omegab = get_model(info_modified_omegab)\n",
        "\n",
        "# Make an evaluation of the posterior so that you can request the requirements\\\n",
        "# Note that you need to do it in the same point as before\n",
        "logposterior_modified_omegab = model_modified_omegab.logposterior(point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmMrZ94gQtq"
      },
      "outputs": [],
      "source": [
        "# Plot the difference in the Cls\n",
        "Cls_modified_omegab = model_modified_omegab.provider.get_Cl(ell_factor=False, units=\"muK2\")\n",
        "\n",
        "# Let's plot them!\n",
        "\n",
        "plt.plot(Cls_modified_omegab['ell'][2:],\n",
        "          Cls_modified_omegab['ell'][2:] * (Cls_modified_omegab['ell'][2:] + 1) * (Cls['tt'][2:]-Cls_modified_omegab['tt'][2:])/Cls['tt'][2:])\n",
        "plt.ylabel(r'$C_\\ell^{TT}$');\n",
        "plt.xlabel(r'$\\ell$');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKWbe816gQtr"
      },
      "outputs": [],
      "source": [
        "# Calculate the difference in the likelihood values for both models\n",
        "\n",
        "logposterior.loglike-logposterior_modified_omegab.loglike"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8XlqJv5pesk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}